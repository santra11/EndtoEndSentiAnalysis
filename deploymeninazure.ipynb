{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd8d40f",
   "metadata": {},
   "source": [
    "## Deployment in azure for the fastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466d2859",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.34.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639a896",
   "metadata": {},
   "source": [
    "### Create the model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a4e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path='./model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f4fda8",
   "metadata": {},
   "source": [
    "### Create the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac0b0d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying AppInsights with name myworkspinsights3bc6a205.\n",
      "Deployed AppInsights with name myworkspinsights3bc6a205. Took 3.9 seconds.\n",
      "Deploying StorageAccount with name myworkspstorageac86dc00d.\n",
      "Deploying KeyVault with name myworkspkeyvault59b6a437.\n",
      "Deployed StorageAccount with name myworkspstorageac86dc00d. Took 23.98 seconds.\n",
      "Deploying Workspace with name myworkspace.\n",
      "Deployed KeyVault with name myworkspkeyvault59b6a437. Took 31.51 seconds.\n",
      "Deployed Workspace with name myworkspace. Took 21.8 seconds.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.create(name='myworkspace',\n",
    "               subscription_id='d2a3b3d7-84df-4290-944a-a1f53aeea99c',\n",
    "               resource_group='Ope711',\n",
    "               location='West Europe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff1c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace(subscription_id='d2a3b3d7-84df-4290-944a-a1f53aeea99c',\n",
    "               resource_group=\"Ope711\",\n",
    "               workspace_name=\"myworkspace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3fded",
   "metadata": {},
   "source": [
    "### Register the model in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d1870a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model sentitweet\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "# Register model\n",
    "model = Model.register(ws, model_name=\"sentitweet\", model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8466022",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentitweet\tsentitweet:1\t1\n"
     ]
    }
   ],
   "source": [
    "print(model.name, model.id, model.version, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eadfaed3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_root = Model.get_model_path(\"sentitweet\", version = 1, _workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "210b535a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7ce76",
   "metadata": {},
   "source": [
    "#### Write the score file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb8668a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Workspace\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import pickle  \n",
    "import nltk\n",
    "\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global tokenizer\n",
    "    global modele\n",
    "    # load model\n",
    "    model_root = Model.get_model_path('sentitweet')\n",
    "    modele=load_model(os.path.join(model_root,'model.h5'))\n",
    "    # tokenizer\n",
    "    token_file = open(os.path.join(model_root, 'tokenizer.pickle'), 'rb')\n",
    "    tokenizer = pickle.load(token_file)\n",
    "    \n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    print(raw_data)\n",
    "    \n",
    "\n",
    "    tokeniz = nltk.RegexpTokenizer(r'\\w+')\n",
    "    raw_data = tokeniz.tokenize(raw_data)\n",
    "\n",
    "    # Tokenize texte\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([raw_data]), maxlen=30)\n",
    "    # Prediction\n",
    "    score = modele.predict([x_test])[0]\n",
    "    # Sentiment\n",
    "    if score <= 0.5: \n",
    "        sentiment = \"negatif\"\n",
    "    elif score> 0.5: \n",
    "        sentiment = \"positif\"\n",
    "    return {\"score\": float(score),\"sentiment\": sentiment}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6c355",
   "metadata": {},
   "source": [
    "### Create the environment and the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "575335ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment(name='myenv')\n",
    "python_packages = ['nltk', 'numpy','tensorflow']\n",
    "for package in python_packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89b43038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"tweets\",  \"method\" : \"FTX\"}, \n",
    "                                               description='Sentiment detection of tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a965327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(environment=env, entry_script='./score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35085ba",
   "metadata": {},
   "source": [
    "### Deploy the model in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5e8589f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-09-21 20:12:36+02:00 Creating Container Registry if not exists.\n",
      "2021-09-21 20:12:37+02:00 Registering the environment.\n",
      "2021-09-21 20:12:41+02:00 Use the existing image.\n",
      "2021-09-21 20:12:41+02:00 Generating deployment configuration..\n",
      "2021-09-21 20:12:43+02:00 Submitting deployment to compute.\n",
      "2021-09-21 20:12:46+02:00 Checking the status of deployment hiver..\n",
      "2021-09-21 20:12:56+02:00 Checking the status of inference endpoint hiver.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(\n",
    "    ws,\n",
    "    \"hiver\",\n",
    "    [model],\n",
    "    inference_config,\n",
    "    deployment_config,\n",
    "    overwrite=True,\n",
    ")\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20973e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-09-21T18:12:49,640315857+00:00 - rsyslog/run \\n2021-09-21T18:12:49,643913373+00:00 - nginx/run \\n2021-09-21T18:12:49,642923769+00:00 - gunicorn/run \\nDynamic Python package installation is disabled.\\nStarting HTTP server\\n2021-09-21T18:12:49,645308779+00:00 - iot-server/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n2021-09-21T18:12:49,852829370+00:00 - iot-server/finish 1 0\\n2021-09-21T18:12:49,854277676+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 20.1.0\\nListening at: http://127.0.0.1:31311 (12)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 41\\n2021-09-21 18:12:50.815630: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library \\'libcudart.so.11.0\\'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_bf9470cf9708630f26b57013e1a0ad56/lib:/azureml-envs/azureml_bf9470cf9708630f26b57013e1a0ad56/lib:\\n2021-09-21 18:12:50.815668: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\\nSPARK_HOME not set. Skipping PySpark Initialization.\\nInitializing logger\\n2021-09-21 18:12:53,461 | root | INFO | Starting up app insights client\\nlogging socket was found. logging is available.\\nlogging socket was found. logging is available.\\n2021-09-21 18:12:53,461 | root | INFO | Starting up request id generator\\n2021-09-21 18:12:53,461 | root | INFO | Starting up app insight hooks\\n2021-09-21 18:12:53,461 | root | INFO | Invoking user\\'s init function\\n2021-09-21 18:12:53.511080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library \\'libcuda.so.1\\'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_bf9470cf9708630f26b57013e1a0ad56/lib:/azureml-envs/azureml_bf9470cf9708630f26b57013e1a0ad56/lib:\\n2021-09-21 18:12:53.511131: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\\n2021-09-21 18:12:53.511158: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wk-caas-3d810b123df84279b69b931c9cb835fe-551d71deda8119af483235): /proc/driver/nvidia/version does not exist\\n2021-09-21 18:12:53.511546: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\\n2021-09-21 18:12:54,055 | root | INFO | Users\\'s init has completed successfully\\n2021-09-21 18:12:54,058 | root | INFO | Skipping middleware: dbg_model_info as it\\'s not enabled.\\n2021-09-21 18:12:54,058 | root | INFO | Skipping middleware: dbg_resource_usage as it\\'s not enabled.\\n2021-09-21 18:12:54,059 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\\n2021-09-21 18:12:56,422 | root | INFO | Swagger file not present\\n2021-09-21 18:12:56,422 | root | INFO | 404\\n127.0.0.1 - - [21/Sep/2021:18:12:56 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n2021-09-21 18:12:58,948 | root | INFO | Swagger file not present\\n2021-09-21 18:12:58,948 | root | INFO | 404\\n127.0.0.1 - - [21/Sep/2021:18:12:58 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8579eb8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://a7f7b42e-9216-48db-8ba5-8809f6f79fdc.westeurope.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce80c05",
   "metadata": {},
   "source": [
    "### We test the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80e9fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.6391505002975464, 'sentiment': 'positif'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://a7f7b42e-9216-48db-8ba5-8809f6f79fdc.westeurope.azurecontainer.io/score\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "raw_data = {\n",
    "    \"query\":\"I love chocolate\",\n",
    "}\n",
    "data = json.dumps(raw_data)\n",
    "response = requests.post(uri, data=raw_data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "670ff2f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.3435966372489929, 'sentiment': 'negatif'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get(\"http://a7f7b42e-9216-48db-8ba5-8809f6f79fdc.westeurope.azurecontainer.io/score\")\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "raw_data = {\n",
    "    \"query\":\"The service was below average and the chips were terribly cold\",\n",
    "}\n",
    "data = json.dumps(raw_data)\n",
    "response = requests.post(uri, data=raw_data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
